{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Iris data set - Keras\n",
    "We goning to demonstrate machine learning prediction on Iris data set. We gonna create model that will predict species of Iris flower by sepal width, sepal length, petal width, and petal length.\n",
    "\n",
    "## Data set\n",
    "[Iris data set](http://mlr.cs.umass.edu/ml/machine-learning-databases/iris/iris.data) is in the cvs format.\n",
    "\n",
    "### Read set and process\n",
    "We gonna use [pandas](http://pandas.pydata.org/) python library to process raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width         type\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "iris_data = pd.read_csv('data/iris.csv')\n",
    "iris_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas library has many nice features where you can specify condions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sepal_length  sepal_width  petal_length  petal_width             type\n",
       "57           4.9          2.4           3.3          1.0  Iris-versicolor"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_data.loc[(iris_data['type'] == \n",
    "               'Iris-versicolor') & (iris_data['sepal_length'] < 5.0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract the data in this format from pandas like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_inputs = iris_data[['sepal_length', 'sepal_width',\n",
    "                             'petal_length', 'petal_width']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can extract the types of Iris flower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_types = iris_data['type'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that you don't mix up the order of the entries all_inputs[5] inputs should correspond to the type in all_types[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.4  3.9  1.7  0.4]  -  Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "print(all_inputs[5],\" - \", all_types[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert all the Iris flower types from data set into respective numbers using [numpy](http://www.numpy.org/) library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "outputs_vals, outputs_ints = np.unique(all_types, return_inverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we split data set into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = np.random.permutation(len(all_inputs))\n",
    "train_inds, test_inds = np.array_split(inds, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also we convert output strings (Iris types) into integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras as kr\n",
    "outputs_vals, outputs_ints = np.unique(all_types, return_inverse=True)\n",
    "outputs_cats = kr.utils.to_categorical(outputs_ints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "And now we populate the training and testing arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train, outputs_train = all_inputs[train_inds], outputs_cats[train_inds]\n",
    "inputs_test,  outputs_test  = all_inputs[test_inds],  outputs_cats[test_inds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the actual creation of the machine learning traing, model and testing we going to use [keras](https://keras.io/).  \n",
    "We start by creating the neural network model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = kr.models.Sequential()\n",
    "model.add(kr.layers.Dense(16, input_shape=(4,)))\n",
    "model.add(kr.layers.Activation(\"sigmoid\"))\n",
    "model.add(kr.layers.Dense(3))\n",
    "model.add(kr.layers.Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Here we created sequential model with input layer which takes 4 inputs  \n",
    " - Next layer consist of 16 neurons to process the 4 inputs\n",
    " - Next layer is using sigmoid function to fit out between -1 and 1.\n",
    " - And finally we are using softmax function to highlight the one dominant output out of all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we configure training model\n",
    "We use adam optimizer and categorical cross entropy as the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training of the model\n",
    "Now we traing the model with training data. We can specify epochs, which is a number of training runs we want to train our neural network with. Also we can specify batch size, which determins number of tests after which our model adjust itself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "75/75 [==============================] - 1s 7ms/step - loss: 1.2309 - acc: 0.3467\n",
      "Epoch 2/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.0938 - acc: 0.3600\n",
      "Epoch 3/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.0355 - acc: 0.4800\n",
      "Epoch 4/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.9984 - acc: 0.5867\n",
      "Epoch 5/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.9648 - acc: 0.6800\n",
      "Epoch 6/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.9150 - acc: 0.7333\n",
      "Epoch 7/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.8626 - acc: 0.7600\n",
      "Epoch 8/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.8105 - acc: 0.6800\n",
      "Epoch 9/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.7656 - acc: 0.7867\n",
      "Epoch 10/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.7271 - acc: 0.6933\n",
      "Epoch 11/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.6912 - acc: 0.7600\n",
      "Epoch 12/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.6592 - acc: 0.7600\n",
      "Epoch 13/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.6368 - acc: 0.7333\n",
      "Epoch 14/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.6081 - acc: 0.7867\n",
      "Epoch 15/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5871 - acc: 0.8000\n",
      "Epoch 16/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5673 - acc: 0.9333\n",
      "Epoch 17/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5478 - acc: 0.8267\n",
      "Epoch 18/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5320 - acc: 0.8400\n",
      "Epoch 19/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5199 - acc: 0.8800\n",
      "Epoch 20/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5063 - acc: 0.8400\n",
      "Epoch 21/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.4927 - acc: 0.8800\n",
      "Epoch 22/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.4814 - acc: 0.8800\n",
      "Epoch 23/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.4713 - acc: 0.9333\n",
      "Epoch 24/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.4606 - acc: 0.8933\n",
      "Epoch 25/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.4521 - acc: 0.9600\n",
      "Epoch 26/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.4423 - acc: 0.9067\n",
      "Epoch 27/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.4330 - acc: 0.9867\n",
      "Epoch 28/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.4248 - acc: 0.9867\n",
      "Epoch 29/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.4174 - acc: 0.9867\n",
      "Epoch 30/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.4104 - acc: 0.9333\n",
      "Epoch 31/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.4034 - acc: 0.9733\n",
      "Epoch 32/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.3953 - acc: 0.9733\n",
      "Epoch 33/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.3874 - acc: 0.9867\n",
      "Epoch 34/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.3800 - acc: 0.9867\n",
      "Epoch 35/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.3746 - acc: 0.9867\n",
      "Epoch 36/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.3666 - acc: 0.9867\n",
      "Epoch 37/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.3585 - acc: 0.9867\n",
      "Epoch 38/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.3522 - acc: 0.9867\n",
      "Epoch 39/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.3448 - acc: 0.9867\n",
      "Epoch 40/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.3397 - acc: 1.0000\n",
      "Epoch 41/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.3334 - acc: 0.9867\n",
      "Epoch 42/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.3295 - acc: 0.9733\n",
      "Epoch 43/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.3202 - acc: 0.9733\n",
      "Epoch 44/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.3170 - acc: 0.9867\n",
      "Epoch 45/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.3072 - acc: 0.9867\n",
      "Epoch 46/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.3037 - acc: 0.9867\n",
      "Epoch 47/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2969 - acc: 0.9867\n",
      "Epoch 48/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2927 - acc: 0.9867\n",
      "Epoch 49/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2842 - acc: 0.9867\n",
      "Epoch 50/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2774 - acc: 0.9867\n",
      "Epoch 51/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2786 - acc: 0.9867\n",
      "Epoch 52/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2691 - acc: 0.9867\n",
      "Epoch 53/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2612 - acc: 0.9867\n",
      "Epoch 54/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2601 - acc: 0.9867\n",
      "Epoch 55/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2553 - acc: 0.9867\n",
      "Epoch 56/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2507 - acc: 0.9867\n",
      "Epoch 57/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2420 - acc: 0.9867\n",
      "Epoch 58/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2398 - acc: 0.9733\n",
      "Epoch 59/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2336 - acc: 0.9733\n",
      "Epoch 60/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2296 - acc: 0.9867\n",
      "Epoch 61/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2261 - acc: 0.9733\n",
      "Epoch 62/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2256 - acc: 0.9733\n",
      "Epoch 63/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2174 - acc: 0.9867\n",
      "Epoch 64/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2138 - acc: 0.9733\n",
      "Epoch 65/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2128 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2045 - acc: 0.9867\n",
      "Epoch 67/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2012 - acc: 0.9867\n",
      "Epoch 68/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1974 - acc: 0.9867\n",
      "Epoch 69/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1959 - acc: 0.9867\n",
      "Epoch 70/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1930 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1865 - acc: 0.9867\n",
      "Epoch 72/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1836 - acc: 0.9867\n",
      "Epoch 73/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1827 - acc: 0.9733\n",
      "Epoch 74/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1792 - acc: 0.9867\n",
      "Epoch 75/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1740 - acc: 0.9867\n",
      "Epoch 76/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1716 - acc: 0.9733\n",
      "Epoch 77/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1683 - acc: 0.9867\n",
      "Epoch 78/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1648 - acc: 0.9867\n",
      "Epoch 79/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1649 - acc: 0.9733\n",
      "Epoch 80/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1614 - acc: 0.9867\n",
      "Epoch 81/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1565 - acc: 0.9867\n",
      "Epoch 82/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1555 - acc: 0.9867\n",
      "Epoch 83/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1546 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1527 - acc: 0.9733A: 0s - loss: 0.1882 - acc: 0.93\n",
      "Epoch 85/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1470 - acc: 0.9733\n",
      "Epoch 86/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1472 - acc: 0.9867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1434 - acc: 0.9733\n",
      "Epoch 88/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1413 - acc: 0.9867\n",
      "Epoch 89/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1414 - acc: 0.9867\n",
      "Epoch 90/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1358 - acc: 0.9867\n",
      "Epoch 91/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1352 - acc: 0.9733\n",
      "Epoch 92/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1315 - acc: 0.9867\n",
      "Epoch 93/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1318 - acc: 0.9867\n",
      "Epoch 94/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1278 - acc: 0.9867\n",
      "Epoch 95/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1284 - acc: 0.9867\n",
      "Epoch 96/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1257 - acc: 0.9733\n",
      "Epoch 97/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1224 - acc: 0.9867\n",
      "Epoch 98/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1230 - acc: 0.9733A: 0s - loss: 0.0963 - acc: 0.96\n",
      "Epoch 99/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1220 - acc: 0.9867\n",
      "Epoch 100/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1176 - acc: 0.9733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4d11de4470>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(inputs_train, outputs_train, epochs=100, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of the model\n",
    "Here we run evaluation on the model we just trained with test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 305us/step\n",
      "\n",
      "\n",
      "Loss:    0.12099\tAccuracy: 96.00 %\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(inputs_test, outputs_test, verbose=1)\n",
    "\n",
    "print(\"\\n\\nLoss: %10.5f\\tAccuracy: %2.2f %%\" % (loss, accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model test\n",
    "And finally we going to test a model we created and trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model prediction in hot vector output: [0 1 0]\n",
      "Model prediction in actual Iris type: Iris-versicolor\n",
      "Actual Iris flower type in data set: Vector: [0 1 0] Type: Iris-versicolor\n"
     ]
    }
   ],
   "source": [
    "prediction = np.around(model.predict(np.expand_dims(inputs_test[24], axis=0))).astype(np.int)[0]\n",
    "print(\"Model prediction in hot vector output: %s\" % prediction)\n",
    "print(\"Model prediction in actual Iris type: %s\" % outputs_vals[prediction.astype(np.bool)][0])\n",
    "print(\"Actual Iris flower type in data set: Vector: %s Type: %s\" % (outputs_test[24].astype(np.int), outputs_vals[prediction.astype(np.bool)][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "As we can see prediction model is behaving as expected and gives us correct prediction with almost 99% perfect accuracy. We can save this model and load and use it for futher predictions later as the model is trained already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d348bb741f7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"iris_model.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.save(\"iris_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapted from: -  `https://github.com/salmanahmad4u/keras-iris/blob/master/iris_nn.py`  \n",
    " - `https://github.com/emerging-technologies/keras-iris`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
